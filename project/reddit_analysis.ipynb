{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "other-shoulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from datetime import datetime, timezone\n",
    "import re\n",
    "from pyspark.sql.functions import col, udf, size\n",
    "from pyspark.sql.types import StringType, ArrayType\n",
    "from operator import add\n",
    "\n",
    "spark_session = SparkSession\\\n",
    "        .builder\\\n",
    "        .master(\"spark://192.168.2.242:7077\") \\\n",
    "        .appName(\"reddit_analysis_t11\")\\\n",
    "        .config(\"spark.dynamicAllocation.enabled\", True)\\\n",
    "        .config(\"spark.shuffle.service.enabled\", True)\\\n",
    "        .config(\"spark.eventLog.enabled\", True)\\\n",
    "        .config(\"spark.eventLog.dir\", \"hdfs://192.168.2.242:9000/user/shared/spark-logs\")\\\n",
    "        .config(\"spark.cores.max\", 8)\\\n",
    "        .getOrCreate()\n",
    "\n",
    "# Old API (RDD) \n",
    "spark_context = spark_session.sparkContext\n",
    "\n",
    "spark_context.setLogLevel(\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "colonial-modeling",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cores = 10\n",
    "df = spark_session.read.json(\"hdfs://192.168.2.242:9000/user/reddit_data/big/strong_scaling/*\")\n",
    "#df.coalesce(cores*2)\n",
    "\n",
    "#print(\"Input Sample:\\n\\n\", df.take(2))\n",
    "#print(\"\\nNumber of partitions:\", df.rdd.getNumPartitions())\n",
    "#print(\"row entries count:\", df.count())\n",
    "\n",
    "#print(\"\\nReddit post schema:\\n\")\n",
    "#df.printSchema()\n",
    "\n",
    "# test converting timestamp\n",
    "first_timestamp = datetime.fromtimestamp(df.first()[\"created_utc\"], tz=timezone.utc)\n",
    "last_timestamp = datetime.fromtimestamp(df.tail(1)[0][\"created_utc\"], tz=timezone.utc)\n",
    "\n",
    "#print(\"First Timestamp of this batch: \", first_timestamp)\n",
    "#print(\"Last Timestamp of this batch\", last_timestamp)\n",
    "\n",
    "\n",
    "start_ts = int(datetime(2000, 1, 1, 0, 0).timestamp())\n",
    "end_ts = int(datetime(2030, 1, 31, 0, 0).timestamp())\n",
    "date_range = range(start_ts, end_ts)\n",
    "#print(\"start_ts:\", start_ts)\n",
    "#print(\"end_ts:\", end_ts)\n",
    "df = df[['created_utc', 'body']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sexual-selection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[created_utc: bigint, body: string]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop everything else\n",
    "#in_range = df[['created_utc', 'body']]\n",
    "#print(type(df.first()[\"created_utc\"]))\n",
    "df = df.filter((end_ts >= df.created_utc) & (df.created_utc >= start_ts))\n",
    "df = df.filter(df.body != '[deleted]')\n",
    "df = df.filter(df.body != '[removed]')\n",
    "df.cache()\n",
    "#in_range.cache()\n",
    "#print(type(df))\n",
    "#print(\"count after filter on date:\", df.count())\n",
    "#print(df.created_utc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "detailed-scanner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(string):\n",
    "    return  re.sub(r'[^A-Za-z ]', '', string.lower())\n",
    "\n",
    "udf_normalize = udf(normalize, StringType())\n",
    "\n",
    "df = df.withColumn('body', udf_normalize(col('body')))\n",
    "#print(df.select(\"body\").take(10))\n",
    "\n",
    "#posts = in_range.select(\"body\").take(10)\n",
    "#single_post = posts[0]\n",
    "# normalize, remove special signs and lower case strings\n",
    "#list_posts = [re.sub(r'[^A-Za-z ]', '', post[\"body\"].lower()) for post in posts]\n",
    "#print(list_posts[0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpine-outline",
   "metadata": {},
   "outputs": [],
   "source": [
    "pres_cand = [\"donald trump\", \"hillary clinton\"]\n",
    "#print(df.take(1))\n",
    "\"\"\" \n",
    "data_rdd = df.rdd\\\n",
    "             .map(lambda line: tuple(set([cand for cand in pres_cand if cand in line[1]])))\\\n",
    "             .filter(lambda match: match != ())\\\n",
    "             .map(lambda word: (word, 1)).reduceByKey(add)\n",
    "\"\"\"\n",
    "\n",
    "def return_candidate(string):\n",
    "    present = [cand for cand in pres_cand if cand in string]\n",
    "    if present == []:\n",
    "        present = ''\n",
    "    return str(present)\n",
    "\n",
    "udf_rc = udf(return_candidate, StringType())\n",
    "# df alternative\n",
    "df = df.withColumn('body', udf_rc(col('body')))\n",
    "df = df.filter(df.body != '')\n",
    "df = df.groupBy('body').count()\n",
    "df.repartition(1).write.csv('save.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designing-crowd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark_context.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-maintenance",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
